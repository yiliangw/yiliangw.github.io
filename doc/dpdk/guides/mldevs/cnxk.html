
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>1. Marvell cnxk Machine Learning Poll Mode Driver &#8212; Data Plane Development Kit 23.11.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DMA Device Drivers" href="../dmadevs/index.html" />
    <link rel="prev" title="Machine Learning Device Driver" href="index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="marvell-cnxk-machine-learning-poll-mode-driver">
<h1><span class="section-number">1. </span>Marvell cnxk Machine Learning Poll Mode Driver</h1>
<p>The cnxk ML poll mode driver provides support for offloading
Machine Learning inference operations to Machine Learning accelerator units
on the <strong>Marvell OCTEON cnxk</strong> SoC family.</p>
<p>The cnxk ML PMD code is organized into multiple files with all file names
starting with cn10k, providing support for CN106XX and CN106XXS.</p>
<p>More information about OCTEON cnxk SoCs may be obtained from <a class="reference external" href="https://www.marvell.com">https://www.marvell.com</a></p>
<section id="supported-octeon-cnxk-socs">
<h2><span class="section-number">1.1. </span>Supported OCTEON cnxk SoCs</h2>
<ul class="simple">
<li><p>CN106XX</p></li>
<li><p>CN106XXS</p></li>
</ul>
</section>
<section id="features">
<h2><span class="section-number">1.2. </span>Features</h2>
<p>The OCTEON cnxk ML PMD provides support for the following set of operations:</p>
<p>Slow-path device and ML model handling:</p>
<ul class="simple">
<li><p>Device probing, configuration and close</p></li>
<li><p>Device start and stop</p></li>
<li><p>Model loading and unloading</p></li>
<li><p>Model start and stop</p></li>
<li><p>Data quantization and dequantization</p></li>
</ul>
<p>Fast-path Inference:</p>
<ul class="simple">
<li><p>Inference execution</p></li>
<li><p>Error handling</p></li>
</ul>
</section>
<section id="compilation-prerequisites">
<h2><span class="section-number">1.3. </span>Compilation Prerequisites</h2>
<p>This driver requires external libraries
to optionally enable support for models compiled using Apache TVM framework.
The following dependencies are not part of DPDK and must be installed separately:</p>
<section id="jansson">
<h3><span class="section-number">1.3.1. </span>Jansson</h3>
<p>This library enables support to parse and read JSON files.</p>
</section>
<section id="dlpack">
<h3><span class="section-number">1.3.2. </span>DLPack</h3>
<p>This library provides headers for open in-memory tensor structures.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>DPDK CNXK ML driver requires DLPack version 0.7</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/dmlc/dlpack.git</span>
<span class="go">cd dlpack</span>
<span class="go">git checkout v0.7 -b v0.7</span>
<span class="go">cmake -S ./ -B build \</span>
<span class="go">   -DCMAKE_INSTALL_PREFIX=&lt;install_prefix&gt; \</span>
<span class="go">   -DBUILD_MOCK=OFF</span>
<span class="go">make -C build</span>
<span class="go">make -C build install</span>
</pre></div>
</div>
<p>When cross-compiling, compiler must be provided to CMake:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">-DCMAKE_C_COMPILER=aarch64-linux-gnu-gcc \</span>
<span class="go">-DCMAKE_CXX_COMPILER=aarch64-linux-gnu-g++</span>
</pre></div>
</div>
</section>
<section id="dmlc">
<h3><span class="section-number">1.3.3. </span>DMLC</h3>
<blockquote>
<div><p>This is a common bricks library for building scalable
and portable distributed machine learning.</p>
</div></blockquote>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/dmlc/dmlc-core.git</span>
<span class="go">cd dmlc-core</span>
<span class="go">git checkout main</span>
<span class="go">cmake -S ./ -B build \</span>
<span class="go">   -DCMAKE_INSTALL_PREFIX=&lt;install_prefix&gt; \</span>
<span class="go">   -DCMAKE_C_FLAGS=&quot;-fpermissive&quot; \</span>
<span class="go">   -DCMAKE_CXX_FLAGS=&quot;-fpermissive&quot; \</span>
<span class="go">   -DUSE_OPENMP=OFF</span>
<span class="go"> make -C build</span>
<span class="go"> make -C build install</span>
</pre></div>
</div>
<p>When cross-compiling, compiler must be provided to CMake:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">-DCMAKE_C_COMPILER=aarch64-linux-gnu-gcc \</span>
<span class="go">-DCMAKE_CXX_COMPILER=aarch64-linux-gnu-g++</span>
</pre></div>
</div>
</section>
<section id="tvm">
<h3><span class="section-number">1.3.4. </span>TVM</h3>
<p>Apache TVM provides a runtime libraries used to execute models
on CPU cores or hardware accelerators.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>DPDK CNXK ML driver requires TVM version 0.10.0</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/apache/tvm.git</span>
<span class="go">cd tvm</span>
<span class="go">git checkout v0.11.0 -b v0.11.0</span>
<span class="go">git submodule update --init</span>
<span class="go">cmake -S ./ -B build \</span>
<span class="go">   -DCMAKE_INSTALL_PREFIX=&lt;install_prefix&gt; \</span>
<span class="go">   -DBUILD_STATIC_RUNTIME=OFF</span>
<span class="go">make -C build</span>
<span class="go">make -C build install</span>
</pre></div>
</div>
<p>When cross-compiling, more options must be provided to CMake:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">-DCMAKE_C_COMPILER=aarch64-linux-gnu-gcc \</span>
<span class="go">-DCMAKE_CXX_COMPILER=aarch64-linux-gnu-g++ \</span>
<span class="go">-DMACHINE_NAME=aarch64-linux-gnu \</span>
<span class="go">-DCMAKE_FIND_ROOT_PATH_MODE_PROGRAM=NEVER \</span>
<span class="go">-DCMAKE_FIND_ROOT_PATH_MODE_LIBRARY=ONLY</span>
</pre></div>
</div>
</section>
<section id="tvmdp">
<h3><span class="section-number">1.3.5. </span>TVMDP</h3>
<blockquote>
<div><p>Marvell’s <a class="reference external" href="https://github.com/MarvellEmbeddedProcessors/tvmdp">TVM Dataplane Library</a>
works as an interface between TVM runtime and DPDK drivers.
TVMDP library provides a simplified C interface
for TVM’s runtime based on C++.</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>TVMDP library is dependent on TVM, dlpack, jansson and dmlc-core libraries.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/MarvellEmbeddedProcessors/tvmdp.git</span>
<span class="go">cd tvmdp</span>
<span class="go">git checkout main</span>
<span class="go">cmake -S ./ -B build \</span>
<span class="go">   -DCMAKE_INSTALL_PREFIX=&lt;install_prefix&gt; \</span>
<span class="go">   -DBUILD_SHARED_LIBS=ON</span>
<span class="go">make -C build</span>
<span class="go">make -C build install</span>
</pre></div>
</div>
<p>When cross-compiling, more options must be provided to CMake:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">-DCMAKE_C_COMPILER=aarch64-linux-gnu-gcc \</span>
<span class="go">-DCMAKE_CXX_COMPILER=aarch64-linux-gnu-g++ \</span>
<span class="go">-DCMAKE_FIND_ROOT_PATH=&lt;install_prefix&gt;</span>
</pre></div>
</div>
</section>
<section id="libarchive">
<h3><span class="section-number">1.3.6. </span>libarchive</h3>
<p>Apache TVM framework generates compiled models as tar archives.
This library enables support to decompress and read archive files
in tar, xz and other formats.</p>
</section>
</section>
<section id="installation">
<h2><span class="section-number">1.4. </span>Installation</h2>
<p>The OCTEON cnxk ML PMD may be compiled natively on an OCTEON cnxk platform
or cross-compiled on an x86 platform.</p>
<p>In order for Meson to find the dependencies above during the configure stage,
it is required to update environment variables as below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">CMAKE_PREFIX_PATH=&#39;&lt;install_prefix&gt;/lib/cmake/tvm:&lt;install_prefix&gt;/lib/cmake/dlpack:&lt;install_prefix&gt;/lib/cmake/dmlc&#39;</span>
<span class="go">PKG_CONFIG_PATH=&#39;&lt;install_prefix&gt;/lib/pkgconfig&#39;</span>
</pre></div>
</div>
<p>Refer to <a class="reference internal" href="../platform/cnxk.html"><span class="doc">Marvell cnxk platform guide</span></a> for instructions to build your DPDK application.</p>
</section>
<section id="initialization">
<h2><span class="section-number">1.5. </span>Initialization</h2>
<p>List the ML PF devices available on cn10k platform:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">lspci -d:a092</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">a092</span></code> is the ML device PF id. You should see output similar to:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">0000:00:10.0 System peripheral: Cavium, Inc. Device a092</span>
</pre></div>
</div>
<p>Bind the ML PF device to the vfio_pci driver:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cd &lt;dpdk directory&gt;</span>
<span class="go">usertools/dpdk-devbind.py -u 0000:00:10.0</span>
<span class="go">usertools/dpdk-devbind.py -b vfio-pci 0000:00:10.0</span>
</pre></div>
</div>
</section>
<section id="vdev-support">
<h2><span class="section-number">1.6. </span>VDEV support</h2>
<p>On platforms which don’t support ML hardware acceleration through PCI device,
the Marvell ML CNXK PMD can execute inference operations on a vdev
with the ML models compiled using Apache TVM framework.</p>
<p>VDEV can be enabled by passing the EAL arguments</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">--vdev ml_mvtvm</span>
</pre></div>
</div>
<p>VDEV can also be used on platforms with ML HW accelerator.
However to use vdev in this case, the PCI device has to be unbound.
When PCI device is bound, creation of vdev is skipped.</p>
</section>
<section id="runtime-config-options">
<h2><span class="section-number">1.7. </span>Runtime Config Options</h2>
<p><strong>Firmware file path</strong> (default <code class="docutils literal notranslate"><span class="pre">/lib/firmware/mlip-fw.bin</span></code>)</p>
<blockquote>
<div><p>Path to the firmware binary to be loaded during device configuration.
The parameter <code class="docutils literal notranslate"><span class="pre">fw_path</span></code> can be used by the user
to load ML firmware from a custom path.</p>
<p>This option is supported only on PCI HW accelerator.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-a 0000:00:10.0,fw_path=&quot;/home/user/ml_fw.bin&quot;
</pre></div>
</div>
<p>With the above configuration, driver loads the firmware from the path
<code class="docutils literal notranslate"><span class="pre">/home/user/ml_fw.bin</span></code>.</p>
</div></blockquote>
<p><strong>Enable DPE warnings</strong> (default <code class="docutils literal notranslate"><span class="pre">1</span></code>)</p>
<blockquote>
<div><p>ML firmware can be configured during load to handle the DPE errors reported
by ML inference engine.
When enabled, firmware would mask the DPE non-fatal hardware errors as warnings.
The parameter <code class="docutils literal notranslate"><span class="pre">enable_dpe_warnings</span></code> is used fo this configuration.</p>
<p>This option is supported only on PCI HW accelerator.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-a 0000:00:10.0,enable_dpe_warnings=0
</pre></div>
</div>
<p>With the above configuration, DPE non-fatal errors reported by HW
are considered as errors.</p>
</div></blockquote>
<p><strong>Model data caching</strong> (default <code class="docutils literal notranslate"><span class="pre">1</span></code>)</p>
<blockquote>
<div><p>Enable caching model data on ML ACC cores.
Enabling this option executes a dummy inference request
in synchronous mode during model start stage.
Caching of model data improves the inferencing throughput / latency for the model.
The parameter <code class="docutils literal notranslate"><span class="pre">cache_model_data</span></code> is used to enable data caching.</p>
<p>This option is supported on PCI HW accelerator and vdev.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-a 0000:00:10.0,cache_model_data=0
</pre></div>
</div>
<p>With the above configuration, model data caching is disabled on HW accelerator.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>--vdev ml_mvtvm,cache_model_data=0
</pre></div>
</div>
<p>With the above configuration, model data caching is disabled on vdev.</p>
</div></blockquote>
<p><strong>OCM allocation mode</strong> (default <code class="docutils literal notranslate"><span class="pre">lowest</span></code>)</p>
<blockquote>
<div><p>Option to specify the method to be used while allocating OCM memory
for a model during model start.
Two modes are supported by the driver.
The parameter <code class="docutils literal notranslate"><span class="pre">ocm_alloc_mode</span></code> is used to select the OCM allocation mode.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">lowest</span></code></dt><dd><p>Allocate OCM for the model from first available free slot.
Search for the free slot is done starting from the lowest tile ID and lowest page ID.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">largest</span></code></dt><dd><p>Allocate OCM for the model from the slot with largest amount of free space.</p>
</dd>
</dl>
<p>This option is supported only on PCI HW accelerator.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-a 0000:00:10.0,ocm_alloc_mode=lowest
</pre></div>
</div>
<p>With the above configuration, OCM allocation for the model would be done
from the first available free slot / from the lowest possible tile ID.</p>
</div></blockquote>
<p><strong>OCM page size</strong> (default <code class="docutils literal notranslate"><span class="pre">16384</span></code>)</p>
<blockquote>
<div><p>Option to specify the page size in bytes to be used for OCM management.
Available OCM is split into multiple pages of specified sizes
and the pages are allocated to the models.
The parameter <code class="docutils literal notranslate"><span class="pre">ocm_page_size</span></code> is used to specify the page size to be used.</p>
<p>Supported page sizes by the driver are 1 KB, 2 KB, 4 KB, 8 KB and 16 KB.
Default page size is 16 KB.</p>
<p>This option is supported only on PCI HW accelerator.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-a 0000:00:10.0,ocm_page_size=8192
</pre></div>
</div>
<p>With the above configuration, page size of OCM is set to 8192 bytes / 8 KB.</p>
</div></blockquote>
<p><strong>Enable hardware queue lock</strong> (default <code class="docutils literal notranslate"><span class="pre">0</span></code>)</p>
<blockquote>
<div><p>Option to select the job request enqueue function to use
to queue the requests to hardware queue.
The parameter <code class="docutils literal notranslate"><span class="pre">hw_queue_lock</span></code> is used to select the enqueue function.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">0</span></code></dt><dd><p>Disable (default), use lock-free version of hardware enqueue function
for job queuing in enqueue burst operation.
To avoid race condition in request queuing to hardware,
disabling <code class="docutils literal notranslate"><span class="pre">hw_queue_lock</span></code> restricts the number of queue-pairs
supported by cnxk driver to 1.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">1</span></code></dt><dd><p>Enable, use spin-lock version of hardware enqueue function for job queuing.
Enabling spinlock version would disable restrictions on the number of queue-pairs
that can be supported by the driver.</p>
</dd>
</dl>
<p>This option is supported only on PCI HW accelerator.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-a 0000:00:10.0,hw_queue_lock=1
</pre></div>
</div>
<p>With the above configuration, spinlock version of hardware enqueue function is used
in the fast path enqueue burst operation.</p>
</div></blockquote>
<p><strong>Maximum queue pairs</strong> (default <code class="docutils literal notranslate"><span class="pre">1</span></code>)</p>
<blockquote>
<div><p>VDEV supports additional EAL arguments to configure the maximum number
of queue-pairs on the ML device through the option <code class="docutils literal notranslate"><span class="pre">max_qps</span></code>.</p>
<p>This option is supported only on vdev.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>--vdev ml_mvtvm,max_qps=4
</pre></div>
</div>
<p>With the above configuration, 4 queue-pairs are created on the vdev.</p>
</div></blockquote>
</section>
<section id="debugging-options">
<h2><span class="section-number">1.8. </span>Debugging Options</h2>
<span id="table-octeon-cnxk-ml-debug-options"></span><table class="docutils align-default" id="id1">
<caption><span class="caption-number">Table 1.12 </span><span class="caption-text">OCTEON cnxk ML PMD debug options</span></caption>
<colgroup>
<col style="width: 4%" />
<col style="width: 17%" />
<col style="width: 79%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#</p></th>
<th class="head"><p>Component</p></th>
<th class="head"><p>EAL log command</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>ML</p></td>
<td><p>–log-level=’pmd.ml.cnxk,8’</p></td>
</tr>
</tbody>
</table>
</section>
<section id="extended-stats">
<h2><span class="section-number">1.9. </span>Extended stats</h2>
<p>Marvell cnxk ML PMD supports reporting the device and model extended statistics.</p>
<p>PMD supports the below list of 4 device extended stats.</p>
<span id="table-octeon-cnxk-ml-device-xstats-names"></span><table class="docutils align-default" id="id2">
<caption><span class="caption-number">Table 1.13 </span><span class="caption-text">OCTEON cnxk ML PMD device xstats names</span></caption>
<colgroup>
<col style="width: 4%" />
<col style="width: 30%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>nb_models_loaded</p></td>
<td><p>Number of models loaded</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>nb_models_unloaded</p></td>
<td><p>Number of models unloaded</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>nb_models_started</p></td>
<td><p>Number of models started</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>nb_models_stopped</p></td>
<td><p>Number of models stopped</p></td>
</tr>
</tbody>
</table>
<p>PMD supports the below list of 6 extended stats types per each model.</p>
<span id="table-octeon-cnxk-ml-model-xstats-names"></span><table class="docutils align-default" id="id3">
<caption><span class="caption-number">Table 1.14 </span><span class="caption-text">OCTEON cnxk ML PMD model xstats names</span></caption>
<colgroup>
<col style="width: 4%" />
<col style="width: 30%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Avg-HW-Latency</p></td>
<td><p>Average hardware latency</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Min-HW-Latency</p></td>
<td><p>Minimum hardware latency</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>Max-HW-Latency</p></td>
<td><p>Maximum hardware latency</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>Avg-FW-Latency</p></td>
<td><p>Average firmware latency</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>Min-FW-Latency</p></td>
<td><p>Minimum firmware latency</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>Max-FW-Latency</p></td>
<td><p>Maximum firmware latency</p></td>
</tr>
</tbody>
</table>
<p>Latency values reported by the PMD through xstats can have units,
either in cycles or nano seconds.
The units of the latency is determined during DPDK initialization
and would depend on the availability of SCLK.
Latencies are reported in nano seconds when the SCLK is available and in cycles otherwise.
Application needs to initialize at least one RVU for the clock to be available.</p>
<p>xstats names are dynamically generated by the PMD and would have the format
<code class="docutils literal notranslate"><span class="pre">Model-&lt;model_id&gt;-Type-&lt;units&gt;</span></code>.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Model-1-Avg-FW-Latency-ns
</pre></div>
</div>
<p>The above xstat name would report average firmware latency in nano seconds
for model ID 1.</p>
<p>The number of xstats made available by the PMD change dynamically.
The number would increase with loading a model and would decrease with unloading a model.
The application needs to update the xstats map after a model is either loaded or unloaded.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/DPDK_logo_vertical_rev_small.png" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../index.html">Data Plane Development Kit</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../linux_gsg/index.html">Getting Started Guide for Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../freebsd_gsg/index.html">Getting Started Guide for FreeBSD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../windows_gsg/index.html">Getting Started Guide for Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_app_ug/index.html">Sample Applications User Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prog_guide/index.html">Programmer’s Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../howto/index.html">HowTo Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools/index.html">DPDK Tools User Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testpmd_app_ug/index.html">Testpmd Application User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nics/index.html">Network Interface Controller Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bbdevs/index.html">Baseband Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cryptodevs/index.html">Crypto Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compressdevs/index.html">Compression Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vdpadevs/index.html">vDPA Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regexdevs/index.html">REGEX Device Drivers</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Machine Learning Device Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dmadevs/index.html">DMA Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpus/index.html">General-Purpose Graphics Processing Unit Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../eventdevs/index.html">Event Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rawdevs/index.html">Rawdev Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mempool/index.html">Mempool Device Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform/index.html">Platform Specific Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">Contributor’s Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rel_notes/index.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Machine Learning Device Driver</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Machine Learning Device Driver</a></li>
      <li>Next: <a href="../dmadevs/index.html" title="next chapter">DMA Device Drivers</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      
      
      
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.3.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/mldevs/cnxk.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>