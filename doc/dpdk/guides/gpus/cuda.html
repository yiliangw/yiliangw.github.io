
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>2. CUDA GPU driver &#8212; Data Plane Development Kit 23.11.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Event Device Drivers" href="../eventdevs/index.html" />
    <link rel="prev" title="1. Overview of GPU Drivers" href="overview.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="cuda-gpu-driver">
<h1><span class="section-number">2. </span>CUDA GPU driver</h1>
<p>The CUDA GPU driver library (<strong>librte_gpu_cuda</strong>) provides support for NVIDIA GPUs.
Information and documentation about these devices can be found on the
<a class="reference external" href="http://www.nvidia.com">NVIDIA website</a>. Help is also provided by the
<a class="reference external" href="https://docs.nvidia.com/cuda">NVIDIA CUDA Toolkit developer zone</a>.</p>
<section id="build-dependencies">
<h2><span class="section-number">2.1. </span>Build dependencies</h2>
<p>The CUDA GPU driver library has a header-only dependency on <code class="docutils literal notranslate"><span class="pre">cuda.h</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaTypedefs.h</span></code>.
To get these headers, there are two options:</p>
<ul class="simple">
<li><p>Install <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit">CUDA Toolkit</a>
(either regular or stubs installation).</p></li>
<li><p>Download these two headers from this <a class="reference external" href="https://gitlab.com/nvidia/headers/cuda-individual/cudart">CUDA headers</a> repository.</p></li>
</ul>
<p>You can point to CUDA header files either with the <code class="docutils literal notranslate"><span class="pre">CFLAGS</span></code> environment variable,
or with the <code class="docutils literal notranslate"><span class="pre">c_args</span></code> Meson option. Examples:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CFLAGS=-I/usr/local/cuda/include</span> <span class="pre">meson</span> <span class="pre">setup</span> <span class="pre">build</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">meson</span> <span class="pre">setup</span> <span class="pre">build</span> <span class="pre">-Dc_args=-I/usr/local/cuda/include</span></code></p></li>
</ul>
<p>If headers are not found, the CUDA GPU driver library is not built.</p>
<section id="cpu-map-gpu-memory">
<h3><span class="section-number">2.1.1. </span>CPU map GPU memory</h3>
<p>To enable this gpudev feature (i.e. implement the <code class="docutils literal notranslate"><span class="pre">rte_gpu_mem_cpu_map</span></code>),
you need the <a class="reference external" href="https://github.com/NVIDIA/gdrcopy">GDRCopy</a> library and driver
installed on your system.</p>
<p>A quick recipe to download, build and run GDRCopy library and driver:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git clone https://github.com/NVIDIA/gdrcopy.git
<span class="gp">$ </span>make
<span class="gp">$ </span><span class="c1"># make install to install GDRCopy library system wide</span>
<span class="gp">$ </span><span class="c1"># Launch gdrdrv kernel module on the system</span>
<span class="gp">$ </span>sudo ./insmod.sh
</pre></div>
</div>
<p>You need to indicate to Meson where GDRCopy header files are as in case of CUDA headers.
An example would be:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>meson setup build -Dc_args<span class="o">=</span><span class="s2">&quot;-I/usr/local/cuda/include -I/path/to/gdrcopy/include&quot;</span>
</pre></div>
</div>
<p>If headers are not found, the CUDA GPU driver library is built without the CPU map capability,
and will return an error if the application invokes the gpudev <code class="docutils literal notranslate"><span class="pre">rte_gpu_mem_cpu_map</span></code> function.</p>
</section>
</section>
<section id="cuda-shared-library">
<h2><span class="section-number">2.2. </span>CUDA Shared Library</h2>
<p>To avoid any system configuration issue, the CUDA API <strong>libcuda.so</strong> shared library
is not linked at building time because of a Meson bug that looks
for <cite>cudart</cite> module even if the <cite>meson.build</cite> file only requires default <cite>cuda</cite> module.</p>
<p><strong>libcuda.so</strong> is loaded at runtime in the <code class="docutils literal notranslate"><span class="pre">cuda_gpu_probe</span></code> function through <code class="docutils literal notranslate"><span class="pre">dlopen</span></code>
when the very first GPU is detected.
If CUDA installation resides in a custom directory,
the environment variable <code class="docutils literal notranslate"><span class="pre">CUDA_PATH_L</span></code> should specify where <code class="docutils literal notranslate"><span class="pre">dlopen</span></code>
can look for <strong>libcuda.so</strong>.</p>
<p>All CUDA API symbols are loaded at runtime as well.
For this reason, to build the CUDA driver library,
no need to install the CUDA library.</p>
<section id="id1">
<h3><span class="section-number">2.2.1. </span>CPU map GPU memory</h3>
<p>Similarly to CUDA shared library, if the <strong>libgdrapi.so</strong> shared library
is not installed in default locations (e.g. /usr/local/lib),
you can use the variable <code class="docutils literal notranslate"><span class="pre">GDRCOPY_PATH_L</span></code>.</p>
<p>As an example, to enable the CPU map feature sanity check,
run the <code class="docutils literal notranslate"><span class="pre">app/test-gpudev</span></code> application with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo <span class="nv">CUDA_PATH_L</span><span class="o">=</span>/path/to/libcuda <span class="nv">GDRCOPY_PATH_L</span><span class="o">=</span>/path/to/libgdrapi ./build/app/dpdk-test-gpudev
</pre></div>
</div>
<p>Additionally, the <code class="docutils literal notranslate"><span class="pre">gdrdrv</span></code> kernel module built with the GDRCopy project
has to be loaded on the system:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>lsmod <span class="p">|</span> egrep gdrdrv
<span class="go">gdrdrv                 20480  0</span>
<span class="go">nvidia              35307520  19 nvidia_uvm,nv_peer_mem,gdrdrv,nvidia_modeset</span>
</pre></div>
</div>
</section>
</section>
<section id="design">
<h2><span class="section-number">2.3. </span>Design</h2>
<p><strong>librte_gpu_cuda</strong> relies on CUDA Driver API (no need for CUDA Runtime API).</p>
<p>Goal of this driver library is not to provide a wrapper for the whole CUDA Driver API.
Instead, the scope is to implement the generic features of gpudev API.
For a CUDA application, integrating the gpudev library functions
using the CUDA driver library is quite straightforward
and doesn’t create any compatibility problem.</p>
<section id="initialization">
<h3><span class="section-number">2.3.1. </span>Initialization</h3>
<p>During initialization, CUDA driver library detects NVIDIA physical GPUs
on the system or specified via EAL device options (e.g. <code class="docutils literal notranslate"><span class="pre">-a</span> <span class="pre">b6:00.0</span></code>).
The driver initializes the CUDA driver environment through <code class="docutils literal notranslate"><span class="pre">cuInit(0)</span></code> function.
For this reason, it’s required to set any CUDA environment configuration before
calling <code class="docutils literal notranslate"><span class="pre">rte_eal_init</span></code> function in the DPDK application.</p>
<p>If the CUDA driver environment has been already initialized, the <code class="docutils literal notranslate"><span class="pre">cuInit(0)</span></code>
in CUDA driver library has no effect.</p>
</section>
<section id="cuda-driver-sub-contexts">
<h3><span class="section-number">2.3.2. </span>CUDA Driver sub-contexts</h3>
<p>After initialization, a CUDA application can create multiple sub-contexts
on GPU physical devices.
Through gpudev library, is possible to register these sub-contexts
in the CUDA driver library as child devices having as parent a GPU physical device.</p>
<p>CUDA driver library also supports <a class="reference external" href="https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf">MPS</a>.</p>
</section>
<section id="gpu-memory-management">
<h3><span class="section-number">2.3.3. </span>GPU memory management</h3>
<p>The CUDA driver library maintains a table of GPU memory addresses allocated
and CPU memory addresses registered associated to the input CUDA context.
Whenever the application tried to deallocate or deregister a memory address,
if the address is not in the table the CUDA driver library will return an error.</p>
</section>
</section>
<section id="features">
<h2><span class="section-number">2.4. </span>Features</h2>
<ul class="simple">
<li><p>Register new child devices, aka CUDA driver contexts.</p></li>
<li><p>Allocate memory on the GPU.</p></li>
<li><p>Register CPU memory to make it visible from GPU.</p></li>
</ul>
</section>
<section id="minimal-requirements">
<h2><span class="section-number">2.5. </span>Minimal requirements</h2>
<p>Minimal requirements to enable the CUDA driver library are:</p>
<ul class="simple">
<li><p>NVIDIA GPU Ampere or Volta</p></li>
<li><p>CUDA 11.4 Driver API or newer</p></li>
</ul>
<p><a class="reference external" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html">GPUDirect RDMA Technology</a>
allows compatible network cards (e.g. ConnectX) to directly send and receive packets
using GPU memory instead of additional memory copies through the CPU system memory.
To enable this technology, system requirements are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html#nvidia-peermem">nvidia-peermem</a>
module running on the system;</p></li>
<li><p>NVIDIA network card ConnectX-5 or newer (BlueField models included);</p></li>
<li><p>DPDK mlx5 PMD enabled;</p></li>
<li><p>To reach the best performance, an additional PCIe switch between GPU and NIC is recommended.</p></li>
</ul>
</section>
<section id="limitations">
<h2><span class="section-number">2.6. </span>Limitations</h2>
<p>Supported only on Linux.</p>
</section>
<section id="supported-gpus">
<h2><span class="section-number">2.7. </span>Supported GPUs</h2>
<p>The following NVIDIA GPU devices are supported by this CUDA driver library:</p>
<ul class="simple">
<li><p>NVIDIA A100 80GB PCIe</p></li>
<li><p>NVIDIA A100 40GB PCIe</p></li>
<li><p>NVIDIA A30 24GB</p></li>
<li><p>NVIDIA A10 24GB</p></li>
<li><p>NVIDIA V100 32GB PCIe</p></li>
<li><p>NVIDIA V100 16GB PCIe</p></li>
</ul>
</section>
<section id="external-references">
<h2><span class="section-number">2.8. </span>External references</h2>
<p>A good example of how to use the GPU CUDA driver library through the gpudev library
is the l2fwd-nv application that can be found <a class="reference external" href="https://github.com/NVIDIA/l2fwd-nv">here</a>.</p>
<p>The application is based on the DPDK example l2fwd,
with GPU memory managed through gpudev library.
It includes a CUDA workload swapping MAC addresses
of packets received in the GPU.</p>
<p>l2fwd-nv is not intended to be used for performance
(testpmd is the good candidate for this).
The goal is to show different use-cases about how a CUDA application can use DPDK to:</p>
<ul class="simple">
<li><p>Allocate memory on GPU device using gpudev library.</p></li>
<li><p>Use that memory to create an external GPU memory mempool.</p></li>
<li><p>Receive packets directly in GPU memory.</p></li>
<li><p>Coordinate the workload on the GPU with the network and CPU activity to receive packets.</p></li>
<li><p>Send modified packets directly from the GPU memory.</p></li>
</ul>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/DPDK_logo_vertical_rev_small.png" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../index.html">Data Plane Development Kit</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../linux_gsg/index.html">Getting Started Guide for Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../freebsd_gsg/index.html">Getting Started Guide for FreeBSD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../windows_gsg/index.html">Getting Started Guide for Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_app_ug/index.html">Sample Applications User Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prog_guide/index.html">Programmer’s Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../howto/index.html">HowTo Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools/index.html">DPDK Tools User Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testpmd_app_ug/index.html">Testpmd Application User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nics/index.html">Network Interface Controller Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bbdevs/index.html">Baseband Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cryptodevs/index.html">Crypto Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compressdevs/index.html">Compression Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vdpadevs/index.html">vDPA Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regexdevs/index.html">REGEX Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mldevs/index.html">Machine Learning Device Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dmadevs/index.html">DMA Device Drivers</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">General-Purpose Graphics Processing Unit Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../eventdevs/index.html">Event Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rawdevs/index.html">Rawdev Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mempool/index.html">Mempool Device Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform/index.html">Platform Specific Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">Contributor’s Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rel_notes/index.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">General-Purpose Graphics Processing Unit Drivers</a><ul>
      <li>Previous: <a href="overview.html" title="previous chapter"><span class="section-number">1. </span>Overview of GPU Drivers</a></li>
      <li>Next: <a href="../eventdevs/index.html" title="next chapter">Event Device Drivers</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      
      
      
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.3.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/gpus/cuda.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>